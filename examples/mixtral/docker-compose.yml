version: '3.8'

services:
  mixtral:
    image: nvcr.io/nvidia/pytorch:25.10-py3
    container_name: mixtral-megatron-bridge

    # GPU configuration
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    # IPC and memory settings for multi-GPU training
    ipc: host
    shm_size: 16gb
    ulimits:
      memlock: -1
      stack: 67108864

    # Volume mounts
    volumes:
      - ../..:/workspace/Megatron-Bridge  # Mount repo root
      - ~/.cache/huggingface:/root/.cache/huggingface  # HF cache
      - ~/.cache/torch:/root/.cache/torch  # Torch cache
      - ./checkpoints:/workspace/checkpoints  # Persistent checkpoints

    # Working directory
    working_dir: /workspace/Megatron-Bridge

    # Environment variables
    environment:
      - CUDA_DEVICE_MAX_CONNECTIONS=1
      - NCCL_DEBUG=INFO
      - PYTHONUNBUFFERED=1
      # Optional: Add your WandB key
      # - WANDB_API_KEY=${WANDB_API_KEY}

    # Keep container running in interactive mode
    stdin_open: true
    tty: true

    # Default command (can be overridden)
    command: /bin/bash
